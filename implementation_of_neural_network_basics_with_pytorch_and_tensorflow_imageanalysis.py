# -*- coding: utf-8 -*-
"""Implementation of Neural Network Basics With PyTorch and TensorFlow_ImageAnalysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f_hx0s3Gbw7YZ2NBIdYKXhxKAvVsPiHW
"""

from PIL import Image
import numpy as np
import cv2

def analyze_image(image_path):
  image = Image.open(image_path)
  # Get the image dimensions
  width, height = image.size
  # Get the image data as a NumPy array
  image_data = np.array(image)
  # Get the color distribution of the image
  color_counts = np.bincount(image_data.flatten())
  # Get the dominant colors of the image
  dominant_colors = np.argsort(color_counts)[-10:][::-1]
  # Get the average intensity of the image
  average_intensity = np.mean(image_data)

  # Analyze the objects in the image (using OpenCV)
  # Convert the image to grayscale
  gray_image = cv2.cvtColor(image_data, cv2.COLOR_BGR2GRAY)

  # Apply edge detection
  edges = cv2.Canny(gray_image, 100, 200)

  # Find contours in the image
  _, contours = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

  # Analyze the contours
  object_count = len(contours)

  # Return the analysis results
  return {
      "width": width,
      "height": height,
      "color_counts": color_counts.tolist(),
      "dominant_colors": dominant_colors.tolist(),
      "average_intensity": average_intensity,
      "object_count": object_count
  }

# Analyze the image
results = analyze_image("/content/Cats.jpg")

# Print the results
print("Image analysis results:")
print(f"Width: {results['width']}")
print(f"Height: {results['height']}")
print(f"Color counts: {results['color_counts']}")
print(f"Dominant colors: {results['dominant_colors']}")
print(f"Average intensity: {results['average_intensity']}")
print(f"Object count: {results['object_count']}")

"""**Implementation of Neural Network Basics With TensorFlow**"""

import tensorflow as tf
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions
from tensorflow.keras.preprocessing import image
import numpy as np

# Load the model
model = ResNet50(weights='imagenet')

# Load the image file, resizing it to 224x224 pixels (required by this model)
img_path = '/content/Cats.jpg'
img = image.load_img(img_path, target_size=(224, 224))

# Convert the image to a numpy array and preprocess it for the model
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)

# Run the image through the model and get the predictions
predictions = model.predict(x)

# Decode predictions into readable results
decoded_predictions = decode_predictions(predictions, top=3)[0]
print('Predictions:', decoded_predictions)

# Output the predictions
for i, (imagenet_id, label, score) in enumerate(decoded_predictions):
    print(f"{i + 1}: {label} ({score:.2f})")

import tensorflow as tf
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.preprocessing import image
from io import BytesIO

with open("/content/Cats.jpg", "rb") as f:
    encoded_image = f.read()

# Load the model
model = ResNet50(weights='imagenet', include_top=True)

# Preprocess the image
img = image.load_img(BytesIO(encoded_image), target_size=(224, 224))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)

# Predict on the image
predictions = model.predict(x)

# Decode the predictions
decoded_predictions = tf.keras.applications.imagenet_utils.decode_predictions(predictions)

# Print the results
print('Predicted:', decoded_predictions[0][0])

import tensorflow as tf
import numpy as np
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.imagenet_utils import decode_predictions
from io import BytesIO

# Load the image
with open("/content/Cats.jpg", "rb") as f:
    encoded_image = f.read()

# Load the model
model = ResNet50(weights='imagenet', include_top=True)

# Preprocess the image
img = image.load_img(BytesIO(encoded_image), target_size=(224, 224))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)

# Predict on the image
predictions = model.predict(x)

# Decode the predictions
decoded_predictions = decode_predictions(predictions)

# Print the results
print('Predicted:', decoded_predictions[0][0])


predicted_labels = decoded_predictions[0]
top_prediction = predicted_labels[0][1]
print('Predicted:', ', '.join([f"{label} ({score:.4f})" for (_, label, score) in predicted_labels]))

predicted_labels = decoded_predictions[0]
top_prediction = predicted_labels[0][1]
print('Predicted:', ', '.join([f"{label} ({score:.4f})" for (_, label, score) in predicted_labels]))

import tensorflow as tf
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions
from tensorflow.keras.preprocessing import image
import numpy as np
import requests

# Load the image
image_path = "/content/Cats.jpg"
img = image.load_img(image_path, target_size=(224, 224))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
img_array = preprocess_input(img_array)

# Load the model
model = ResNet50(weights='imagenet')

# Predict on the image
predictions = model.predict(img_array)

# Decode the predictions
decoded_predictions = decode_predictions(predictions, top=5)[0]

# Fetch class labels
LABELS_URL = "https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json"
labels = requests.get(LABELS_URL).json()

# Print the results
print('Predicted:')
for _, label, score in decoded_predictions:
    print(f"{label} ({score:.4f})")

"""**Implementation of Neural Network Basics With PyTorch**"""

import torch
from torchvision import models, transforms
from PIL import Image
import requests

# Load the ResNet50 model pre-trained on ImageNet
model = models.resnet50(pretrained=True)
model.eval()

# Define transformations to preprocess the image
preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Load and preprocess the image
img_path = '/content/Cats.jpg'
input_image = Image.open(img_path)
input_tensor = preprocess(input_image)
input_batch = input_tensor.unsqueeze(0)

# Perform inference
with torch.no_grad():
    predictions = model(input_batch)

# Fetch and decode the class labels
LABELS_URL = "https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json"
labels = requests.get(LABELS_URL).json()

# Get the top predictions
_, indices = torch.topk(predictions, 3)
indices = indices.squeeze(0).tolist()

# Print the predictions
print('Predictions:')
for idx in indices:
    print(f"{labels[idx]}")

import torch
from torchvision import models, transforms
from PIL import Image
import requests

# Load the ResNet50 model pre-trained on ImageNet
model = models.resnet50(pretrained=True)
model.eval()

# Define transformations to preprocess the image
preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Load and preprocess the image
img_path = '/content/Cats.jpg'
input_image = Image.open(img_path)
input_tensor = preprocess(input_image)
input_batch = input_tensor.unsqueeze(0)

# Perform inference
with torch.no_grad():
    predictions = model(input_batch)

# Fetch and decode the class labels
LABELS_URL = "https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json"
labels = requests.get(LABELS_URL).json()

# Get the top prediction
_, index = torch.max(predictions, 1)
predicted_label = labels[index.item()]

# Print the predicted label
print('Predicted:', predicted_label)

"""
> **Code Below:**
*   After obtaining the predictions, it directly fetches and decodes the class labels using the LABELS_URL and prints the top prediction along with the top 5 predictions.
*   It is structured to use the torchvision library for loading and preprocessing images, making it more aligned with PyTorch's conventions.
*   It directly obtains the predictions and handles them together with the labels retrieval and printing."""

import torch
from torchvision import models, transforms
from PIL import Image
import requests

# Load the ResNet50 model pre-trained on ImageNet
model = models.resnet50(pretrained=True)
model.eval()

# Define transformations to preprocess the image
preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Load and preprocess the image
img_path = '/content/Cats.jpg'
input_image = Image.open(img_path)
input_tensor = preprocess(input_image)
input_batch = input_tensor.unsqueeze(0)

# Perform inference
with torch.no_grad():
    predictions = model(input_batch)

# Fetch and decode the class labels
LABELS_URL = "https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json"
labels = requests.get(LABELS_URL).json()

# Get the top prediction
_, index = torch.max(predictions, 1)
predicted_label = labels[index.item()]

# Get all predictions
_, indices = torch.topk(predictions, 5)
indices = indices.squeeze(0).tolist()
predicted_labels = [(labels[idx], predictions[0][idx].item()) for idx in indices]

# Print the top prediction
print('Predicted:', predicted_label)

# Print all predictions
print('Top 5 Predictions:')
for label, score in predicted_labels:
    print(f"{label} ({score:.4f})")

"""> **Code Below:**
*   After obtaining the predictions, it only extracts the indices of the top 5 predictions and then fetches the class labels using the LABELS_URL. It then prints each prediction separately, including the label and its corresponding score.
*   It directly uses the PIL library for image loading and torchvision for image preprocessing, but it separates the preprocessing and prediction steps more explicitly.
*   It separates the prediction and label retrieval steps, making it clearer what each step is responsible for.
"""

import torch
import torchvision.transforms as transforms
from PIL import Image
import requests
from torchvision import models

# Load the image
image_path = "/content/Cats.jpg"
input_image = Image.open(image_path)

# Define transformations
preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Preprocess the image
input_tensor = preprocess(input_image)
input_batch = input_tensor.unsqueeze(0)

# Load the model
model = models.resnet50(pretrained=True)
model.eval()

# Predict on the image
with torch.no_grad():
    predictions = model(input_batch)

# Decode the predictions
_, indices = torch.topk(predictions, 5)
indices = indices.squeeze(0).tolist()

# Fetch class labels
LABELS_URL = "https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json"
labels = requests.get(LABELS_URL).json()

# Print the results
print('Predicted:')
for idx in indices:
    print(f"{labels[idx]} ({predictions[0][idx]:.4f})")